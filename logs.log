2025-06-27 14:36:09,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 14:36:09,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 14:36:09,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 14:36:09,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 14:55:51,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 14:55:51,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 14:55:51,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 14:55:51,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 14:55:53,847:INFO:PyCaret ClassificationExperiment
2025-06-27 14:55:53,847:INFO:Logging name: Survived_classification
2025-06-27 14:55:53,847:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-27 14:55:53,847:INFO:version 3.3.2
2025-06-27 14:55:53,847:INFO:Initializing setup()
2025-06-27 14:55:53,847:INFO:self.USI: ede0
2025-06-27 14:55:53,847:INFO:self._variable_keys: {'USI', 'target_param', 'fix_imbalance', 'is_multiclass', 'y_train', 'idx', 'seed', 'X_test', 'X', 'exp_id', 'n_jobs_param', 'fold_shuffle_param', 'fold_groups_param', '_ml_usecase', 'data', 'memory', 'y', 'exp_name_log', 'logging_param', 'html_param', 'y_test', '_available_plots', 'gpu_param', 'X_train', 'pipeline', 'log_plots_param', 'fold_generator', 'gpu_n_jobs_param'}
2025-06-27 14:55:53,847:INFO:Checking environment
2025-06-27 14:55:53,847:INFO:python_version: 3.11.9
2025-06-27 14:55:53,847:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-27 14:55:53,849:INFO:machine: AMD64
2025-06-27 14:55:53,849:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-27 14:55:53,853:INFO:Memory: svmem(total=34156609536, available=16625901568, percent=51.3, used=17530707968, free=16625901568)
2025-06-27 14:55:53,853:INFO:Physical Core: 4
2025-06-27 14:55:53,853:INFO:Logical Core: 8
2025-06-27 14:55:53,853:INFO:Checking libraries
2025-06-27 14:55:53,853:INFO:System:
2025-06-27 14:55:53,853:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-27 14:55:53,853:INFO:executable: c:\Users\hp\Downloads\titanic\venv55412\Scripts\python.exe
2025-06-27 14:55:53,853:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-27 14:55:53,853:INFO:PyCaret required dependencies:
2025-06-27 14:55:54,096:INFO:                 pip: 24.0
2025-06-27 14:55:54,096:INFO:          setuptools: 65.5.0
2025-06-27 14:55:54,096:INFO:             pycaret: 3.3.2
2025-06-27 14:55:54,096:INFO:             IPython: 9.3.0
2025-06-27 14:55:54,096:INFO:          ipywidgets: 8.1.7
2025-06-27 14:55:54,096:INFO:                tqdm: 4.67.1
2025-06-27 14:55:54,096:INFO:               numpy: 1.26.4
2025-06-27 14:55:54,096:INFO:              pandas: 2.1.4
2025-06-27 14:55:54,096:INFO:              jinja2: 3.1.6
2025-06-27 14:55:54,096:INFO:               scipy: 1.11.4
2025-06-27 14:55:54,096:INFO:              joblib: 1.3.2
2025-06-27 14:55:54,096:INFO:             sklearn: 1.4.2
2025-06-27 14:55:54,096:INFO:                pyod: 2.0.5
2025-06-27 14:55:54,096:INFO:            imblearn: 0.13.0
2025-06-27 14:55:54,096:INFO:   category_encoders: 2.7.0
2025-06-27 14:55:54,096:INFO:            lightgbm: 4.6.0
2025-06-27 14:55:54,096:INFO:               numba: 0.61.2
2025-06-27 14:55:54,096:INFO:            requests: 2.32.4
2025-06-27 14:55:54,096:INFO:          matplotlib: 3.7.5
2025-06-27 14:55:54,096:INFO:          scikitplot: 0.3.7
2025-06-27 14:55:54,098:INFO:         yellowbrick: 1.5
2025-06-27 14:55:54,098:INFO:              plotly: 5.24.1
2025-06-27 14:55:54,098:INFO:    plotly-resampler: Not installed
2025-06-27 14:55:54,098:INFO:             kaleido: 1.0.0
2025-06-27 14:55:54,099:INFO:           schemdraw: 0.15
2025-06-27 14:55:54,099:INFO:         statsmodels: 0.14.4
2025-06-27 14:55:54,099:INFO:              sktime: 0.26.0
2025-06-27 14:55:54,099:INFO:               tbats: 1.1.3
2025-06-27 14:55:54,099:INFO:            pmdarima: 2.0.4
2025-06-27 14:55:54,099:INFO:              psutil: 7.0.0
2025-06-27 14:55:54,099:INFO:          markupsafe: 3.0.2
2025-06-27 14:55:54,099:INFO:             pickle5: Not installed
2025-06-27 14:55:54,099:INFO:         cloudpickle: 3.1.1
2025-06-27 14:55:54,099:INFO:         deprecation: 2.1.0
2025-06-27 14:55:54,099:INFO:              xxhash: 3.5.0
2025-06-27 14:55:54,099:INFO:           wurlitzer: Not installed
2025-06-27 14:55:54,101:INFO:PyCaret optional dependencies:
2025-06-27 14:55:54,160:INFO:                shap: Not installed
2025-06-27 14:55:54,160:INFO:           interpret: Not installed
2025-06-27 14:55:54,160:INFO:                umap: Not installed
2025-06-27 14:55:54,160:INFO:     ydata_profiling: Not installed
2025-06-27 14:55:54,160:INFO:  explainerdashboard: Not installed
2025-06-27 14:55:54,160:INFO:             autoviz: Not installed
2025-06-27 14:55:54,160:INFO:           fairlearn: Not installed
2025-06-27 14:55:54,160:INFO:          deepchecks: Not installed
2025-06-27 14:55:54,160:INFO:             xgboost: Not installed
2025-06-27 14:55:54,160:INFO:            catboost: Not installed
2025-06-27 14:55:54,160:INFO:              kmodes: Not installed
2025-06-27 14:55:54,160:INFO:             mlxtend: Not installed
2025-06-27 14:55:54,160:INFO:       statsforecast: Not installed
2025-06-27 14:55:54,160:INFO:        tune_sklearn: Not installed
2025-06-27 14:55:54,160:INFO:                 ray: Not installed
2025-06-27 14:55:54,160:INFO:            hyperopt: Not installed
2025-06-27 14:55:54,164:INFO:              optuna: Not installed
2025-06-27 14:55:54,164:INFO:               skopt: Not installed
2025-06-27 14:55:54,164:INFO:              mlflow: Not installed
2025-06-27 14:55:54,164:INFO:              gradio: Not installed
2025-06-27 14:55:54,164:INFO:             fastapi: Not installed
2025-06-27 14:55:54,164:INFO:             uvicorn: Not installed
2025-06-27 14:55:54,164:INFO:              m2cgen: Not installed
2025-06-27 14:55:54,164:INFO:           evidently: Not installed
2025-06-27 14:55:54,164:INFO:               fugue: Not installed
2025-06-27 14:55:54,164:INFO:           streamlit: Not installed
2025-06-27 14:55:54,165:INFO:             prophet: Not installed
2025-06-27 14:55:54,165:INFO:None
2025-06-27 14:55:54,166:INFO:Set up data.
2025-06-27 14:55:54,188:INFO:Set up folding strategy.
2025-06-27 14:55:54,188:INFO:Set up train/test split.
2025-06-27 14:55:54,206:INFO:Set up index.
2025-06-27 14:55:54,212:INFO:Assigning column types.
2025-06-27 14:55:54,223:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-27 14:55:54,304:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 14:55:54,314:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 14:55:54,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:54,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:54,534:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 14:55:54,544:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 14:55:54,628:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:54,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:54,628:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-27 14:55:54,771:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 14:55:54,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:54,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:54,944:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 14:55:55,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:55,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:55,013:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-27 14:55:55,145:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:55,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:55,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:55,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:55,317:INFO:Preparing preprocessing pipeline...
2025-06-27 14:55:55,317:INFO:Set up simple imputation.
2025-06-27 14:55:55,334:INFO:Set up encoding of ordinal features.
2025-06-27 14:55:55,334:INFO:Set up encoding of categorical features.
2025-06-27 14:55:55,334:INFO:Set up polynomial features.
2025-06-27 14:55:55,334:INFO:Set up removing multicollinearity.
2025-06-27 14:55:55,334:INFO:Set up feature normalization.
2025-06-27 14:55:55,817:INFO:Finished creating preprocessing pipeline.
2025-06-27 14:55:55,851:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imp...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-06-27 14:55:55,851:INFO:Creating final display dataframe.
2025-06-27 14:55:56,715:INFO:Setup _display_container:                     Description                    Value
0                    Session id                      124
1                        Target                 Survived
2                   Target type                   Binary
3           Original data shape                (712, 12)
4        Transformed data shape                (712, 53)
5   Transformed train set shape                (498, 53)
6    Transformed test set shape                (214, 53)
7              Numeric features                        6
8          Categorical features                        5
9      Rows with missing values                    79.9%
10                   Preprocess                     True
11              Imputation type                   simple
12           Numeric imputation                     mean
13       Categorical imputation                     mode
14     Maximum one-hot encoding                       25
15              Encoding method                     None
16          Polynomial features                     True
17            Polynomial degree                        2
18     Remove multicollinearity                     True
19  Multicollinearity threshold                      0.9
20                    Normalize                     True
21             Normalize method                   zscore
22               Fold Generator          StratifiedKFold
23                  Fold Number                       10
24                     CPU Jobs                       -1
25                      Use GPU                    False
26               Log Experiment                    False
27              Experiment Name  Survived_classification
28                          USI                     ede0
2025-06-27 14:55:56,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:56,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:56,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:56,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:55:56,980:INFO:setup() successfully completed in 3.15s...............
2025-06-27 14:56:14,118:INFO:gpu_param set to False
2025-06-27 14:56:14,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:56:14,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:56:14,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:56:14,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 14:56:14,503:INFO:Initializing compare_models()
2025-06-27 14:56:14,504:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-06-27 14:56:14,504:INFO:Checking exceptions
2025-06-27 14:56:58,821:INFO:Initializing compare_models()
2025-06-27 14:56:58,823:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-06-27 14:56:58,823:INFO:Checking exceptions
2025-06-27 14:56:58,834:INFO:Preparing display monitor
2025-06-27 14:56:58,899:INFO:Initializing Logistic Regression
2025-06-27 14:56:58,901:INFO:Total runtime is 0.0 minutes
2025-06-27 14:56:58,923:INFO:SubProcess create_model() called ==================================
2025-06-27 14:56:58,923:INFO:Initializing create_model()
2025-06-27 14:56:58,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:56:58,927:INFO:Checking exceptions
2025-06-27 14:56:58,927:INFO:Importing libraries
2025-06-27 14:56:58,927:INFO:Copying training dataset
2025-06-27 14:56:58,951:INFO:Defining folds
2025-06-27 14:56:58,951:INFO:Declaring metric variables
2025-06-27 14:56:58,970:INFO:Importing untrained model
2025-06-27 14:56:58,981:INFO:Logistic Regression Imported successfully
2025-06-27 14:56:58,999:INFO:Starting cross validation
2025-06-27 14:56:59,005:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:10,261:INFO:Calculating mean and std
2025-06-27 14:57:10,265:INFO:Creating metrics dataframe
2025-06-27 14:57:10,275:INFO:Uploading results into container
2025-06-27 14:57:10,279:INFO:Uploading model into container now
2025-06-27 14:57:10,281:INFO:_master_model_container: 1
2025-06-27 14:57:10,281:INFO:_display_container: 2
2025-06-27 14:57:10,283:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=124, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-27 14:57:10,285:INFO:create_model() successfully completed......................................
2025-06-27 14:57:10,480:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:10,480:INFO:Creating metrics dataframe
2025-06-27 14:57:10,498:INFO:Initializing K Neighbors Classifier
2025-06-27 14:57:10,498:INFO:Total runtime is 0.1933215061823527 minutes
2025-06-27 14:57:10,504:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:10,506:INFO:Initializing create_model()
2025-06-27 14:57:10,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:10,506:INFO:Checking exceptions
2025-06-27 14:57:10,507:INFO:Importing libraries
2025-06-27 14:57:10,507:INFO:Copying training dataset
2025-06-27 14:57:10,511:INFO:Defining folds
2025-06-27 14:57:10,511:INFO:Declaring metric variables
2025-06-27 14:57:10,524:INFO:Importing untrained model
2025-06-27 14:57:10,534:INFO:K Neighbors Classifier Imported successfully
2025-06-27 14:57:10,554:INFO:Starting cross validation
2025-06-27 14:57:10,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:12,098:INFO:Calculating mean and std
2025-06-27 14:57:12,098:INFO:Creating metrics dataframe
2025-06-27 14:57:12,103:INFO:Uploading results into container
2025-06-27 14:57:12,105:INFO:Uploading model into container now
2025-06-27 14:57:12,107:INFO:_master_model_container: 2
2025-06-27 14:57:12,107:INFO:_display_container: 2
2025-06-27 14:57:12,107:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-27 14:57:12,107:INFO:create_model() successfully completed......................................
2025-06-27 14:57:12,258:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:12,260:INFO:Creating metrics dataframe
2025-06-27 14:57:12,284:INFO:Initializing Naive Bayes
2025-06-27 14:57:12,284:INFO:Total runtime is 0.22307916084925333 minutes
2025-06-27 14:57:12,295:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:12,295:INFO:Initializing create_model()
2025-06-27 14:57:12,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:12,298:INFO:Checking exceptions
2025-06-27 14:57:12,298:INFO:Importing libraries
2025-06-27 14:57:12,298:INFO:Copying training dataset
2025-06-27 14:57:12,313:INFO:Defining folds
2025-06-27 14:57:12,313:INFO:Declaring metric variables
2025-06-27 14:57:12,336:INFO:Importing untrained model
2025-06-27 14:57:12,351:INFO:Naive Bayes Imported successfully
2025-06-27 14:57:12,388:INFO:Starting cross validation
2025-06-27 14:57:12,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:12,995:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:12,997:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:13,005:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:13,011:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:13,011:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:13,023:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:13,029:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:13,037:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:13,423:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:13,423:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:13,440:INFO:Calculating mean and std
2025-06-27 14:57:13,441:INFO:Creating metrics dataframe
2025-06-27 14:57:13,445:INFO:Uploading results into container
2025-06-27 14:57:13,445:INFO:Uploading model into container now
2025-06-27 14:57:13,448:INFO:_master_model_container: 3
2025-06-27 14:57:13,448:INFO:_display_container: 2
2025-06-27 14:57:13,449:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-27 14:57:13,449:INFO:create_model() successfully completed......................................
2025-06-27 14:57:13,570:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:13,570:INFO:Creating metrics dataframe
2025-06-27 14:57:13,592:INFO:Initializing Decision Tree Classifier
2025-06-27 14:57:13,592:INFO:Total runtime is 0.24488885800043741 minutes
2025-06-27 14:57:13,600:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:13,600:INFO:Initializing create_model()
2025-06-27 14:57:13,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:13,600:INFO:Checking exceptions
2025-06-27 14:57:13,600:INFO:Importing libraries
2025-06-27 14:57:13,600:INFO:Copying training dataset
2025-06-27 14:57:13,610:INFO:Defining folds
2025-06-27 14:57:13,610:INFO:Declaring metric variables
2025-06-27 14:57:13,621:INFO:Importing untrained model
2025-06-27 14:57:13,633:INFO:Decision Tree Classifier Imported successfully
2025-06-27 14:57:13,651:INFO:Starting cross validation
2025-06-27 14:57:13,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:14,263:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:14,271:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:14,284:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:14,589:INFO:Calculating mean and std
2025-06-27 14:57:14,592:INFO:Creating metrics dataframe
2025-06-27 14:57:14,594:INFO:Uploading results into container
2025-06-27 14:57:14,596:INFO:Uploading model into container now
2025-06-27 14:57:14,598:INFO:_master_model_container: 4
2025-06-27 14:57:14,598:INFO:_display_container: 2
2025-06-27 14:57:14,598:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best')
2025-06-27 14:57:14,598:INFO:create_model() successfully completed......................................
2025-06-27 14:57:14,732:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:14,732:INFO:Creating metrics dataframe
2025-06-27 14:57:14,748:INFO:Initializing SVM - Linear Kernel
2025-06-27 14:57:14,748:INFO:Total runtime is 0.26415608723958334 minutes
2025-06-27 14:57:14,756:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:14,756:INFO:Initializing create_model()
2025-06-27 14:57:14,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:14,756:INFO:Checking exceptions
2025-06-27 14:57:14,756:INFO:Importing libraries
2025-06-27 14:57:14,756:INFO:Copying training dataset
2025-06-27 14:57:14,768:INFO:Defining folds
2025-06-27 14:57:14,768:INFO:Declaring metric variables
2025-06-27 14:57:14,779:INFO:Importing untrained model
2025-06-27 14:57:14,784:INFO:SVM - Linear Kernel Imported successfully
2025-06-27 14:57:14,802:INFO:Starting cross validation
2025-06-27 14:57:14,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:15,694:INFO:Calculating mean and std
2025-06-27 14:57:15,696:INFO:Creating metrics dataframe
2025-06-27 14:57:15,698:INFO:Uploading results into container
2025-06-27 14:57:15,698:INFO:Uploading model into container now
2025-06-27 14:57:15,700:INFO:_master_model_container: 5
2025-06-27 14:57:15,700:INFO:_display_container: 2
2025-06-27 14:57:15,700:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=124, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-27 14:57:15,700:INFO:create_model() successfully completed......................................
2025-06-27 14:57:15,806:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:15,806:INFO:Creating metrics dataframe
2025-06-27 14:57:15,834:INFO:Initializing Ridge Classifier
2025-06-27 14:57:15,834:INFO:Total runtime is 0.28225228389104207 minutes
2025-06-27 14:57:15,843:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:15,846:INFO:Initializing create_model()
2025-06-27 14:57:15,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:15,846:INFO:Checking exceptions
2025-06-27 14:57:15,846:INFO:Importing libraries
2025-06-27 14:57:15,846:INFO:Copying training dataset
2025-06-27 14:57:15,859:INFO:Defining folds
2025-06-27 14:57:15,859:INFO:Declaring metric variables
2025-06-27 14:57:15,868:INFO:Importing untrained model
2025-06-27 14:57:15,879:INFO:Ridge Classifier Imported successfully
2025-06-27 14:57:15,891:INFO:Starting cross validation
2025-06-27 14:57:15,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:16,467:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:16,478:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:16,490:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:16,508:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:16,508:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:16,512:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:16,518:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:16,525:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:16,808:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:16,808:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:16,829:INFO:Calculating mean and std
2025-06-27 14:57:16,831:INFO:Creating metrics dataframe
2025-06-27 14:57:16,833:INFO:Uploading results into container
2025-06-27 14:57:16,835:INFO:Uploading model into container now
2025-06-27 14:57:16,835:INFO:_master_model_container: 6
2025-06-27 14:57:16,835:INFO:_display_container: 2
2025-06-27 14:57:16,835:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=124, solver='auto',
                tol=0.0001)
2025-06-27 14:57:16,835:INFO:create_model() successfully completed......................................
2025-06-27 14:57:16,956:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:16,956:INFO:Creating metrics dataframe
2025-06-27 14:57:16,981:INFO:Initializing Random Forest Classifier
2025-06-27 14:57:16,981:INFO:Total runtime is 0.3013689835866292 minutes
2025-06-27 14:57:16,988:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:16,988:INFO:Initializing create_model()
2025-06-27 14:57:16,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:16,991:INFO:Checking exceptions
2025-06-27 14:57:16,991:INFO:Importing libraries
2025-06-27 14:57:16,991:INFO:Copying training dataset
2025-06-27 14:57:17,000:INFO:Defining folds
2025-06-27 14:57:17,003:INFO:Declaring metric variables
2025-06-27 14:57:17,012:INFO:Importing untrained model
2025-06-27 14:57:17,021:INFO:Random Forest Classifier Imported successfully
2025-06-27 14:57:17,081:INFO:Starting cross validation
2025-06-27 14:57:17,085:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:18,332:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:18,470:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:19,048:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:19,079:INFO:Calculating mean and std
2025-06-27 14:57:19,081:INFO:Creating metrics dataframe
2025-06-27 14:57:19,085:INFO:Uploading results into container
2025-06-27 14:57:19,085:INFO:Uploading model into container now
2025-06-27 14:57:19,087:INFO:_master_model_container: 7
2025-06-27 14:57:19,087:INFO:_display_container: 2
2025-06-27 14:57:19,087:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=124, verbose=0,
                       warm_start=False)
2025-06-27 14:57:19,087:INFO:create_model() successfully completed......................................
2025-06-27 14:57:19,225:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:19,225:INFO:Creating metrics dataframe
2025-06-27 14:57:19,240:INFO:Initializing Quadratic Discriminant Analysis
2025-06-27 14:57:19,247:INFO:Total runtime is 0.3391314665476481 minutes
2025-06-27 14:57:19,251:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:19,251:INFO:Initializing create_model()
2025-06-27 14:57:19,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:19,251:INFO:Checking exceptions
2025-06-27 14:57:19,251:INFO:Importing libraries
2025-06-27 14:57:19,251:INFO:Copying training dataset
2025-06-27 14:57:19,264:INFO:Defining folds
2025-06-27 14:57:19,264:INFO:Declaring metric variables
2025-06-27 14:57:19,270:INFO:Importing untrained model
2025-06-27 14:57:19,280:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-27 14:57:19,297:INFO:Starting cross validation
2025-06-27 14:57:19,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:19,746:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 14:57:19,755:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 14:57:19,778:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 14:57:19,780:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 14:57:19,819:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 14:57:19,819:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 14:57:19,821:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 14:57:19,825:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 14:57:19,874:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:19,949:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:19,951:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:20,143:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 14:57:20,153:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 14:57:20,216:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:20,235:INFO:Calculating mean and std
2025-06-27 14:57:20,239:INFO:Creating metrics dataframe
2025-06-27 14:57:20,250:INFO:Uploading results into container
2025-06-27 14:57:20,252:INFO:Uploading model into container now
2025-06-27 14:57:20,252:INFO:_master_model_container: 8
2025-06-27 14:57:20,256:INFO:_display_container: 2
2025-06-27 14:57:20,258:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-27 14:57:20,258:INFO:create_model() successfully completed......................................
2025-06-27 14:57:20,436:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:20,438:INFO:Creating metrics dataframe
2025-06-27 14:57:20,454:INFO:Initializing Ada Boost Classifier
2025-06-27 14:57:20,454:INFO:Total runtime is 0.35924576123555496 minutes
2025-06-27 14:57:20,460:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:20,460:INFO:Initializing create_model()
2025-06-27 14:57:20,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:20,462:INFO:Checking exceptions
2025-06-27 14:57:20,462:INFO:Importing libraries
2025-06-27 14:57:20,462:INFO:Copying training dataset
2025-06-27 14:57:20,472:INFO:Defining folds
2025-06-27 14:57:20,474:INFO:Declaring metric variables
2025-06-27 14:57:20,482:INFO:Importing untrained model
2025-06-27 14:57:20,489:INFO:Ada Boost Classifier Imported successfully
2025-06-27 14:57:20,535:INFO:Starting cross validation
2025-06-27 14:57:20,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:20,994:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 14:57:20,997:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 14:57:20,999:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 14:57:20,999:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 14:57:21,011:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 14:57:21,019:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 14:57:21,019:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 14:57:21,028:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 14:57:21,120:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:21,126:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:21,137:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:21,145:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:21,145:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:21,166:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:21,348:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 14:57:21,350:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 14:57:21,460:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:21,463:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:21,481:INFO:Calculating mean and std
2025-06-27 14:57:21,483:INFO:Creating metrics dataframe
2025-06-27 14:57:21,483:INFO:Uploading results into container
2025-06-27 14:57:21,483:INFO:Uploading model into container now
2025-06-27 14:57:21,490:INFO:_master_model_container: 9
2025-06-27 14:57:21,490:INFO:_display_container: 2
2025-06-27 14:57:21,490:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=124)
2025-06-27 14:57:21,490:INFO:create_model() successfully completed......................................
2025-06-27 14:57:21,626:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:21,626:INFO:Creating metrics dataframe
2025-06-27 14:57:21,640:INFO:Initializing Gradient Boosting Classifier
2025-06-27 14:57:21,640:INFO:Total runtime is 0.3790187835693359 minutes
2025-06-27 14:57:21,653:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:21,656:INFO:Initializing create_model()
2025-06-27 14:57:21,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:21,657:INFO:Checking exceptions
2025-06-27 14:57:21,657:INFO:Importing libraries
2025-06-27 14:57:21,657:INFO:Copying training dataset
2025-06-27 14:57:21,658:INFO:Defining folds
2025-06-27 14:57:21,658:INFO:Declaring metric variables
2025-06-27 14:57:21,672:INFO:Importing untrained model
2025-06-27 14:57:21,683:INFO:Gradient Boosting Classifier Imported successfully
2025-06-27 14:57:21,702:INFO:Starting cross validation
2025-06-27 14:57:21,707:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:22,620:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:22,634:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:22,659:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:22,664:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:23,126:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:23,148:INFO:Calculating mean and std
2025-06-27 14:57:23,150:INFO:Creating metrics dataframe
2025-06-27 14:57:23,154:INFO:Uploading results into container
2025-06-27 14:57:23,154:INFO:Uploading model into container now
2025-06-27 14:57:23,156:INFO:_master_model_container: 10
2025-06-27 14:57:23,156:INFO:_display_container: 2
2025-06-27 14:57:23,157:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=124, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-27 14:57:23,157:INFO:create_model() successfully completed......................................
2025-06-27 14:57:23,281:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:23,281:INFO:Creating metrics dataframe
2025-06-27 14:57:23,296:INFO:Initializing Linear Discriminant Analysis
2025-06-27 14:57:23,296:INFO:Total runtime is 0.4066234668095906 minutes
2025-06-27 14:57:23,309:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:23,309:INFO:Initializing create_model()
2025-06-27 14:57:23,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:23,310:INFO:Checking exceptions
2025-06-27 14:57:23,310:INFO:Importing libraries
2025-06-27 14:57:23,311:INFO:Copying training dataset
2025-06-27 14:57:23,319:INFO:Defining folds
2025-06-27 14:57:23,319:INFO:Declaring metric variables
2025-06-27 14:57:23,326:INFO:Importing untrained model
2025-06-27 14:57:23,330:INFO:Linear Discriminant Analysis Imported successfully
2025-06-27 14:57:23,348:INFO:Starting cross validation
2025-06-27 14:57:23,355:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:23,882:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:23,909:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:23,913:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:23,919:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:23,919:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:23,938:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:24,178:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:24,184:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:24,198:INFO:Calculating mean and std
2025-06-27 14:57:24,200:INFO:Creating metrics dataframe
2025-06-27 14:57:24,205:INFO:Uploading results into container
2025-06-27 14:57:24,207:INFO:Uploading model into container now
2025-06-27 14:57:24,208:INFO:_master_model_container: 11
2025-06-27 14:57:24,208:INFO:_display_container: 2
2025-06-27 14:57:24,209:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-27 14:57:24,209:INFO:create_model() successfully completed......................................
2025-06-27 14:57:24,342:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:24,342:INFO:Creating metrics dataframe
2025-06-27 14:57:24,360:INFO:Initializing Extra Trees Classifier
2025-06-27 14:57:24,360:INFO:Total runtime is 0.4243433793385823 minutes
2025-06-27 14:57:24,363:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:24,363:INFO:Initializing create_model()
2025-06-27 14:57:24,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:24,367:INFO:Checking exceptions
2025-06-27 14:57:24,367:INFO:Importing libraries
2025-06-27 14:57:24,367:INFO:Copying training dataset
2025-06-27 14:57:24,374:INFO:Defining folds
2025-06-27 14:57:24,377:INFO:Declaring metric variables
2025-06-27 14:57:24,385:INFO:Importing untrained model
2025-06-27 14:57:24,393:INFO:Extra Trees Classifier Imported successfully
2025-06-27 14:57:24,410:INFO:Starting cross validation
2025-06-27 14:57:24,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:26,042:INFO:Calculating mean and std
2025-06-27 14:57:26,044:INFO:Creating metrics dataframe
2025-06-27 14:57:26,048:INFO:Uploading results into container
2025-06-27 14:57:26,050:INFO:Uploading model into container now
2025-06-27 14:57:26,050:INFO:_master_model_container: 12
2025-06-27 14:57:26,050:INFO:_display_container: 2
2025-06-27 14:57:26,050:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=124, verbose=0,
                     warm_start=False)
2025-06-27 14:57:26,053:INFO:create_model() successfully completed......................................
2025-06-27 14:57:26,197:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:26,197:INFO:Creating metrics dataframe
2025-06-27 14:57:26,217:INFO:Initializing Light Gradient Boosting Machine
2025-06-27 14:57:26,217:INFO:Total runtime is 0.4552933573722839 minutes
2025-06-27 14:57:26,223:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:26,224:INFO:Initializing create_model()
2025-06-27 14:57:26,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:26,224:INFO:Checking exceptions
2025-06-27 14:57:26,224:INFO:Importing libraries
2025-06-27 14:57:26,224:INFO:Copying training dataset
2025-06-27 14:57:26,224:INFO:Defining folds
2025-06-27 14:57:26,224:INFO:Declaring metric variables
2025-06-27 14:57:26,240:INFO:Importing untrained model
2025-06-27 14:57:26,252:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-27 14:57:26,266:INFO:Starting cross validation
2025-06-27 14:57:26,273:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:27,252:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:27,300:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:27,329:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:27,343:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:27,496:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:27,639:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:27,686:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:27,898:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:27,914:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:27,935:INFO:Calculating mean and std
2025-06-27 14:57:27,937:INFO:Creating metrics dataframe
2025-06-27 14:57:27,941:INFO:Uploading results into container
2025-06-27 14:57:27,943:INFO:Uploading model into container now
2025-06-27 14:57:27,943:INFO:_master_model_container: 13
2025-06-27 14:57:27,943:INFO:_display_container: 2
2025-06-27 14:57:27,945:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=124, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-27 14:57:27,947:INFO:create_model() successfully completed......................................
2025-06-27 14:57:28,083:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:28,083:INFO:Creating metrics dataframe
2025-06-27 14:57:28,100:INFO:Initializing Dummy Classifier
2025-06-27 14:57:28,100:INFO:Total runtime is 0.48668317000071204 minutes
2025-06-27 14:57:28,105:INFO:SubProcess create_model() called ==================================
2025-06-27 14:57:28,105:INFO:Initializing create_model()
2025-06-27 14:57:28,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4765B7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:28,105:INFO:Checking exceptions
2025-06-27 14:57:28,105:INFO:Importing libraries
2025-06-27 14:57:28,107:INFO:Copying training dataset
2025-06-27 14:57:28,113:INFO:Defining folds
2025-06-27 14:57:28,113:INFO:Declaring metric variables
2025-06-27 14:57:28,125:INFO:Importing untrained model
2025-06-27 14:57:28,131:INFO:Dummy Classifier Imported successfully
2025-06-27 14:57:28,147:INFO:Starting cross validation
2025-06-27 14:57:28,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 14:57:28,681:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:28,683:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:28,689:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:28,692:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:28,699:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:28,699:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:28,713:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:28,722:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:28,944:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:28,949:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 14:57:28,960:INFO:Calculating mean and std
2025-06-27 14:57:28,962:INFO:Creating metrics dataframe
2025-06-27 14:57:28,965:INFO:Uploading results into container
2025-06-27 14:57:28,965:INFO:Uploading model into container now
2025-06-27 14:57:28,967:INFO:_master_model_container: 14
2025-06-27 14:57:28,967:INFO:_display_container: 2
2025-06-27 14:57:28,967:INFO:DummyClassifier(constant=None, random_state=124, strategy='prior')
2025-06-27 14:57:28,967:INFO:create_model() successfully completed......................................
2025-06-27 14:57:29,097:INFO:SubProcess create_model() end ==================================
2025-06-27 14:57:29,097:INFO:Creating metrics dataframe
2025-06-27 14:57:29,117:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-06-27 14:57:29,134:INFO:Initializing create_model()
2025-06-27 14:57:29,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 14:57:29,134:INFO:Checking exceptions
2025-06-27 14:57:29,140:INFO:Importing libraries
2025-06-27 14:57:29,140:INFO:Copying training dataset
2025-06-27 14:57:29,146:INFO:Defining folds
2025-06-27 14:57:29,149:INFO:Declaring metric variables
2025-06-27 14:57:29,149:INFO:Importing untrained model
2025-06-27 14:57:29,149:INFO:Declaring custom model
2025-06-27 14:57:29,150:INFO:K Neighbors Classifier Imported successfully
2025-06-27 14:57:29,154:INFO:Cross validation set to False
2025-06-27 14:57:29,154:INFO:Fitting Model
2025-06-27 14:57:29,318:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-27 14:57:29,318:INFO:create_model() successfully completed......................................
2025-06-27 14:57:29,489:INFO:_master_model_container: 14
2025-06-27 14:57:29,489:INFO:_display_container: 2
2025-06-27 14:57:29,489:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-27 14:57:29,489:INFO:compare_models() successfully completed......................................
2025-06-27 15:01:05,102:INFO:Initializing tune_model()
2025-06-27 15:01:05,103:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-06-27 15:01:05,103:INFO:Checking exceptions
2025-06-27 15:01:05,137:INFO:Copying training dataset
2025-06-27 15:01:05,147:INFO:Checking base model
2025-06-27 15:01:05,147:INFO:Base model : K Neighbors Classifier
2025-06-27 15:01:05,155:INFO:Declaring metric variables
2025-06-27 15:01:05,162:INFO:Defining Hyperparameters
2025-06-27 15:01:05,371:INFO:Tuning with n_jobs=-1
2025-06-27 15:01:05,371:INFO:Initializing RandomizedSearchCV
2025-06-27 15:01:13,423:INFO:best_params: {'actual_estimator__weights': 'distance', 'actual_estimator__n_neighbors': 10, 'actual_estimator__metric': 'manhattan'}
2025-06-27 15:01:13,425:INFO:Hyperparameter search completed
2025-06-27 15:01:13,425:INFO:SubProcess create_model() called ==================================
2025-06-27 15:01:13,427:INFO:Initializing create_model()
2025-06-27 15:01:13,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E476429810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'weights': 'distance', 'n_neighbors': 10, 'metric': 'manhattan'})
2025-06-27 15:01:13,427:INFO:Checking exceptions
2025-06-27 15:01:13,429:INFO:Importing libraries
2025-06-27 15:01:13,429:INFO:Copying training dataset
2025-06-27 15:01:13,444:INFO:Defining folds
2025-06-27 15:01:13,444:INFO:Declaring metric variables
2025-06-27 15:01:13,454:INFO:Importing untrained model
2025-06-27 15:01:13,456:INFO:Declaring custom model
2025-06-27 15:01:13,467:INFO:K Neighbors Classifier Imported successfully
2025-06-27 15:01:13,489:INFO:Starting cross validation
2025-06-27 15:01:13,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:01:14,657:INFO:Calculating mean and std
2025-06-27 15:01:14,660:INFO:Creating metrics dataframe
2025-06-27 15:01:14,673:INFO:Finalizing model
2025-06-27 15:01:15,058:INFO:Uploading results into container
2025-06-27 15:01:15,062:INFO:Uploading model into container now
2025-06-27 15:01:15,062:INFO:_master_model_container: 15
2025-06-27 15:01:15,064:INFO:_display_container: 3
2025-06-27 15:01:15,064:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance')
2025-06-27 15:01:15,066:INFO:create_model() successfully completed......................................
2025-06-27 15:01:15,276:INFO:SubProcess create_model() end ==================================
2025-06-27 15:01:15,276:INFO:choose_better activated
2025-06-27 15:01:15,287:INFO:SubProcess create_model() called ==================================
2025-06-27 15:01:15,287:INFO:Initializing create_model()
2025-06-27 15:01:15,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:01:15,287:INFO:Checking exceptions
2025-06-27 15:01:15,292:INFO:Importing libraries
2025-06-27 15:01:15,292:INFO:Copying training dataset
2025-06-27 15:01:15,302:INFO:Defining folds
2025-06-27 15:01:15,302:INFO:Declaring metric variables
2025-06-27 15:01:15,302:INFO:Importing untrained model
2025-06-27 15:01:15,302:INFO:Declaring custom model
2025-06-27 15:01:15,302:INFO:K Neighbors Classifier Imported successfully
2025-06-27 15:01:15,302:INFO:Starting cross validation
2025-06-27 15:01:15,309:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:01:16,430:INFO:Calculating mean and std
2025-06-27 15:01:16,430:INFO:Creating metrics dataframe
2025-06-27 15:01:16,434:INFO:Finalizing model
2025-06-27 15:01:16,806:INFO:Uploading results into container
2025-06-27 15:01:16,806:INFO:Uploading model into container now
2025-06-27 15:01:16,808:INFO:_master_model_container: 16
2025-06-27 15:01:16,808:INFO:_display_container: 4
2025-06-27 15:01:16,808:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-27 15:01:16,808:INFO:create_model() successfully completed......................................
2025-06-27 15:01:16,988:INFO:SubProcess create_model() end ==================================
2025-06-27 15:01:16,991:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') result for Accuracy is 0.7872
2025-06-27 15:01:16,992:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance') result for Accuracy is 0.7912
2025-06-27 15:01:16,993:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance') is best model
2025-06-27 15:01:16,993:INFO:choose_better completed
2025-06-27 15:01:17,056:INFO:_master_model_container: 16
2025-06-27 15:01:17,056:INFO:_display_container: 3
2025-06-27 15:01:17,061:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance')
2025-06-27 15:01:17,061:INFO:tune_model() successfully completed......................................
2025-06-27 15:01:28,360:INFO:Initializing evaluate_model()
2025-06-27 15:01:28,360:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-27 15:01:28,386:INFO:Initializing plot_model()
2025-06-27 15:01:28,386:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-06-27 15:01:28,386:INFO:Checking exceptions
2025-06-27 15:01:28,392:INFO:Preloading libraries
2025-06-27 15:01:28,394:INFO:Copying training dataset
2025-06-27 15:01:28,394:INFO:Plot type: pipeline
2025-06-27 15:01:29,021:INFO:Visual Rendered Successfully
2025-06-27 15:01:29,156:INFO:plot_model() successfully completed......................................
2025-06-27 15:01:34,401:INFO:Initializing plot_model()
2025-06-27 15:01:34,401:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance'), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-06-27 15:01:34,403:INFO:Checking exceptions
2025-06-27 15:01:34,410:INFO:Preloading libraries
2025-06-27 15:01:34,410:INFO:Copying training dataset
2025-06-27 15:01:34,412:INFO:Plot type: parameter
2025-06-27 15:01:34,420:INFO:Visual Rendered Successfully
2025-06-27 15:01:34,602:INFO:plot_model() successfully completed......................................
2025-06-27 15:01:58,796:INFO:Initializing finalize_model()
2025-06-27 15:01:58,797:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-27 15:01:58,797:INFO:Finalizing KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance')
2025-06-27 15:01:58,808:INFO:Initializing create_model()
2025-06-27 15:01:58,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:01:58,808:INFO:Checking exceptions
2025-06-27 15:01:58,812:INFO:Importing libraries
2025-06-27 15:01:58,812:INFO:Copying training dataset
2025-06-27 15:01:58,818:INFO:Defining folds
2025-06-27 15:01:58,819:INFO:Declaring metric variables
2025-06-27 15:01:58,819:INFO:Importing untrained model
2025-06-27 15:01:58,819:INFO:Declaring custom model
2025-06-27 15:01:58,823:INFO:K Neighbors Classifier Imported successfully
2025-06-27 15:01:58,829:INFO:Cross validation set to False
2025-06-27 15:01:58,831:INFO:Fitting Model
2025-06-27 15:01:59,471:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='manhattan', metric_params=None,
                                      n_jobs=-1, n_neighbors=10, p=2,
                                      weights='distance'))],
         verbose=False)
2025-06-27 15:01:59,471:INFO:create_model() successfully completed......................................
2025-06-27 15:01:59,601:INFO:_master_model_container: 16
2025-06-27 15:01:59,601:INFO:_display_container: 3
2025-06-27 15:01:59,677:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='manhattan', metric_params=None,
                                      n_jobs=-1, n_neighbors=10, p=2,
                                      weights='distance'))],
         verbose=False)
2025-06-27 15:01:59,677:INFO:finalize_model() successfully completed......................................
2025-06-27 15:02:12,256:INFO:Initializing predict_model()
2025-06-27 15:02:12,256:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='manhattan', metric_params=None,
                                      n_jobs=-1, n_neighbors=10, p=2,
                                      weights='distance'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E478BFA020>)
2025-06-27 15:02:12,256:INFO:Checking exceptions
2025-06-27 15:02:12,256:INFO:Preloading libraries
2025-06-27 15:02:12,263:INFO:Set up data.
2025-06-27 15:02:12,281:INFO:Set up index.
2025-06-27 15:05:44,563:INFO:Initializing save_model()
2025-06-27 15:05:44,563:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='manhattan', metric_params=None,
                                      n_jobs=-1, n_neighbors=10, p=2,
                                      weights='distance'))],
         verbose=False), model_name=final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imp...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-06-27 15:05:44,569:INFO:Adding model into prep_pipe
2025-06-27 15:05:44,569:WARNING:Only Model saved as it was a pipeline.
2025-06-27 15:05:44,585:INFO:final_model.pkl saved in current working directory
2025-06-27 15:05:44,616:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='manhattan', metric_params=None,
                                      n_jobs=-1, n_neighbors=10, p=2,
                                      weights='distance'))],
         verbose=False)
2025-06-27 15:05:44,616:INFO:save_model() successfully completed......................................
2025-06-27 15:06:00,754:INFO:Initializing load_model()
2025-06-27 15:06:00,754:INFO:load_model(model_name=final_model, platform=None, authentication=None, verbose=True)
2025-06-27 15:39:08,422:INFO:Initializing blend_models()
2025-06-27 15:39:08,422:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator_list=[KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance')], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-06-27 15:39:08,423:INFO:Checking exceptions
2025-06-27 15:39:08,458:INFO:Importing libraries
2025-06-27 15:39:08,460:INFO:Copying training dataset
2025-06-27 15:39:08,470:INFO:Getting model names
2025-06-27 15:39:08,481:INFO:SubProcess create_model() called ==================================
2025-06-27 15:39:08,488:INFO:Initializing create_model()
2025-06-27 15:39:08,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=VotingClassifier(estimators=[('K Neighbors Classifier',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='minkowski',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=5,
                                                   p=2, weights='uniform')),
                             ('K Neighbors Classifier_1',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='manhattan',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=10,
                                                   p=2, weights='distance'))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E47B139150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:39:08,488:INFO:Checking exceptions
2025-06-27 15:39:08,488:INFO:Importing libraries
2025-06-27 15:39:08,488:INFO:Copying training dataset
2025-06-27 15:39:08,502:INFO:Defining folds
2025-06-27 15:39:08,502:INFO:Declaring metric variables
2025-06-27 15:39:08,510:INFO:Importing untrained model
2025-06-27 15:39:08,510:INFO:Declaring custom model
2025-06-27 15:39:08,525:INFO:Voting Classifier Imported successfully
2025-06-27 15:39:08,541:INFO:Starting cross validation
2025-06-27 15:39:08,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:39:21,627:INFO:Calculating mean and std
2025-06-27 15:39:21,629:INFO:Creating metrics dataframe
2025-06-27 15:39:21,645:INFO:Finalizing model
2025-06-27 15:39:22,068:INFO:Uploading results into container
2025-06-27 15:39:22,068:INFO:Uploading model into container now
2025-06-27 15:39:22,070:INFO:_master_model_container: 17
2025-06-27 15:39:22,070:INFO:_display_container: 5
2025-06-27 15:39:22,076:INFO:VotingClassifier(estimators=[('K Neighbors Classifier',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='minkowski',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=5,
                                                   p=2, weights='uniform')),
                             ('K Neighbors Classifier_1',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='manhattan',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=10,
                                                   p=2, weights='distance'))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-06-27 15:39:22,076:INFO:create_model() successfully completed......................................
2025-06-27 15:39:22,450:INFO:SubProcess create_model() end ==================================
2025-06-27 15:39:22,472:INFO:_master_model_container: 17
2025-06-27 15:39:22,472:INFO:_display_container: 5
2025-06-27 15:39:22,476:INFO:VotingClassifier(estimators=[('K Neighbors Classifier',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='minkowski',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=5,
                                                   p=2, weights='uniform')),
                             ('K Neighbors Classifier_1',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='manhattan',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=10,
                                                   p=2, weights='distance'))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-06-27 15:39:22,478:INFO:blend_models() successfully completed......................................
2025-06-27 15:39:30,928:INFO:Initializing stack_models()
2025-06-27 15:39:30,929:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator_list=[KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance')], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-06-27 15:39:30,929:INFO:Checking exceptions
2025-06-27 15:39:30,932:INFO:Defining meta model
2025-06-27 15:39:30,978:INFO:Getting model names
2025-06-27 15:39:30,980:INFO:[('K Neighbors Classifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')), ('K Neighbors Classifier_1', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance'))]
2025-06-27 15:39:30,991:INFO:SubProcess create_model() called ==================================
2025-06-27 15:39:31,000:INFO:Initializing create_model()
2025-06-27 15:39:31,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=StackingClassifier(cv=5,
                   estimators=[('K Neighbors Classifier',
                                KNeighborsClassifier(algorithm='auto',
                                                     leaf_size=30,
                                                     metric='minkowski',
                                                     metric_params=None,
                                                     n_jobs=-1, n_neighbors=5,
                                                     p=2, weights='uniform')),
                               ('K Neighbors Classifier_1',
                                KNeighborsClassifier(algorithm='auto',
                                                     leaf_size=30,
                                                     metric='manhattan',
                                                     metric_params=None,
                                                     n_jobs=-1, n_neighbors=10,
                                                     p=2,
                                                     weights='distance'))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=124,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E47B03F890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:39:31,001:INFO:Checking exceptions
2025-06-27 15:39:31,001:INFO:Importing libraries
2025-06-27 15:39:31,001:INFO:Copying training dataset
2025-06-27 15:39:31,017:INFO:Defining folds
2025-06-27 15:39:31,017:INFO:Declaring metric variables
2025-06-27 15:39:31,030:INFO:Importing untrained model
2025-06-27 15:39:31,030:INFO:Declaring custom model
2025-06-27 15:39:31,042:INFO:Stacking Classifier Imported successfully
2025-06-27 15:39:31,064:INFO:Starting cross validation
2025-06-27 15:39:31,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:39:32,804:INFO:Calculating mean and std
2025-06-27 15:39:32,809:INFO:Creating metrics dataframe
2025-06-27 15:39:32,816:INFO:Finalizing model
2025-06-27 15:39:33,238:INFO:Uploading results into container
2025-06-27 15:39:33,241:INFO:Uploading model into container now
2025-06-27 15:39:33,241:INFO:_master_model_container: 18
2025-06-27 15:39:33,241:INFO:_display_container: 6
2025-06-27 15:39:33,253:INFO:StackingClassifier(cv=5,
                   estimators=[('K Neighbors Classifier',
                                KNeighborsClassifier(algorithm='auto',
                                                     leaf_size=30,
                                                     metric='minkowski',
                                                     metric_params=None,
                                                     n_jobs=-1, n_neighbors=5,
                                                     p=2, weights='uniform')),
                               ('K Neighbors Classifier_1',
                                KNeighborsClassifier(algorithm='auto',
                                                     leaf_size=30,
                                                     metric='manhattan',
                                                     metric_params=None,
                                                     n_jobs=-1, n_neighbors=10,
                                                     p=2,
                                                     weights='distance'))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=124,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2025-06-27 15:39:33,253:INFO:create_model() successfully completed......................................
2025-06-27 15:39:33,446:INFO:SubProcess create_model() end ==================================
2025-06-27 15:39:33,467:INFO:_master_model_container: 18
2025-06-27 15:39:33,467:INFO:_display_container: 6
2025-06-27 15:39:33,471:INFO:StackingClassifier(cv=5,
                   estimators=[('K Neighbors Classifier',
                                KNeighborsClassifier(algorithm='auto',
                                                     leaf_size=30,
                                                     metric='minkowski',
                                                     metric_params=None,
                                                     n_jobs=-1, n_neighbors=5,
                                                     p=2, weights='uniform')),
                               ('K Neighbors Classifier_1',
                                KNeighborsClassifier(algorithm='auto',
                                                     leaf_size=30,
                                                     metric='manhattan',
                                                     metric_params=None,
                                                     n_jobs=-1, n_neighbors=10,
                                                     p=2,
                                                     weights='distance'))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=124,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2025-06-27 15:39:33,471:INFO:stack_models() successfully completed......................................
2025-06-27 15:40:40,186:INFO:Initializing finalize_model()
2025-06-27 15:40:40,189:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-27 15:40:40,189:INFO:Finalizing KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance')
2025-06-27 15:40:40,196:INFO:Initializing create_model()
2025-06-27 15:40:40,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
                     weights='distance'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:40:40,196:INFO:Checking exceptions
2025-06-27 15:40:40,201:INFO:Importing libraries
2025-06-27 15:40:40,201:INFO:Copying training dataset
2025-06-27 15:40:40,206:INFO:Defining folds
2025-06-27 15:40:40,206:INFO:Declaring metric variables
2025-06-27 15:40:40,208:INFO:Importing untrained model
2025-06-27 15:40:40,208:INFO:Declaring custom model
2025-06-27 15:40:40,209:INFO:K Neighbors Classifier Imported successfully
2025-06-27 15:40:40,211:INFO:Cross validation set to False
2025-06-27 15:40:40,211:INFO:Fitting Model
2025-06-27 15:40:40,588:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='manhattan', metric_params=None,
                                      n_jobs=-1, n_neighbors=10, p=2,
                                      weights='distance'))],
         verbose=False)
2025-06-27 15:40:40,588:INFO:create_model() successfully completed......................................
2025-06-27 15:40:40,793:INFO:_master_model_container: 18
2025-06-27 15:40:40,793:INFO:_display_container: 6
2025-06-27 15:40:40,848:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='manhattan', metric_params=None,
                                      n_jobs=-1, n_neighbors=10, p=2,
                                      weights='distance'))],
         verbose=False)
2025-06-27 15:40:40,848:INFO:finalize_model() successfully completed......................................
2025-06-27 15:40:41,108:INFO:Initializing predict_model()
2025-06-27 15:40:41,108:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E472C94ED0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='manhattan', metric_params=None,
                                      n_jobs=-1, n_neighbors=10, p=2,
                                      weights='distance'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E47D9845E0>)
2025-06-27 15:40:41,108:INFO:Checking exceptions
2025-06-27 15:40:41,108:INFO:Preloading libraries
2025-06-27 15:40:41,112:INFO:Set up data.
2025-06-27 15:40:41,131:INFO:Set up index.
2025-06-27 15:53:31,852:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 15:53:31,852:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 15:53:31,852:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 15:53:31,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 15:53:34,636:INFO:PyCaret ClassificationExperiment
2025-06-27 15:53:34,636:INFO:Logging name: Survived_classification
2025-06-27 15:53:34,636:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-27 15:53:34,636:INFO:version 3.3.2
2025-06-27 15:53:34,636:INFO:Initializing setup()
2025-06-27 15:53:34,636:INFO:self.USI: b0f8
2025-06-27 15:53:34,636:INFO:self._variable_keys: {'X_test', 'gpu_param', 'data', 'USI', 'pipeline', 'fold_generator', 'X', 'fix_imbalance', 'y', 'html_param', 'X_train', 'y_train', 'idx', 'y_test', 'fold_groups_param', 'n_jobs_param', 'exp_id', 'target_param', 'logging_param', 'exp_name_log', '_available_plots', 'memory', 'gpu_n_jobs_param', 'fold_shuffle_param', 'seed', 'is_multiclass', 'log_plots_param', '_ml_usecase'}
2025-06-27 15:53:34,636:INFO:Checking environment
2025-06-27 15:53:34,636:INFO:python_version: 3.11.9
2025-06-27 15:53:34,636:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-27 15:53:34,636:INFO:machine: AMD64
2025-06-27 15:53:34,637:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-27 15:53:34,641:INFO:Memory: svmem(total=34156609536, available=16642859008, percent=51.3, used=17513750528, free=16642859008)
2025-06-27 15:53:34,641:INFO:Physical Core: 4
2025-06-27 15:53:34,641:INFO:Logical Core: 8
2025-06-27 15:53:34,641:INFO:Checking libraries
2025-06-27 15:53:34,641:INFO:System:
2025-06-27 15:53:34,641:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-27 15:53:34,641:INFO:executable: c:\Users\hp\Downloads\titanic\venv55412\Scripts\python.exe
2025-06-27 15:53:34,641:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-27 15:53:34,642:INFO:PyCaret required dependencies:
2025-06-27 15:53:34,710:INFO:                 pip: 24.0
2025-06-27 15:53:34,710:INFO:          setuptools: 65.5.0
2025-06-27 15:53:34,710:INFO:             pycaret: 3.3.2
2025-06-27 15:53:34,710:INFO:             IPython: 9.3.0
2025-06-27 15:53:34,711:INFO:          ipywidgets: 8.1.7
2025-06-27 15:53:34,711:INFO:                tqdm: 4.67.1
2025-06-27 15:53:34,711:INFO:               numpy: 1.26.4
2025-06-27 15:53:34,711:INFO:              pandas: 2.1.4
2025-06-27 15:53:34,711:INFO:              jinja2: 3.1.6
2025-06-27 15:53:34,711:INFO:               scipy: 1.11.4
2025-06-27 15:53:34,711:INFO:              joblib: 1.3.2
2025-06-27 15:53:34,711:INFO:             sklearn: 1.4.2
2025-06-27 15:53:34,711:INFO:                pyod: 2.0.5
2025-06-27 15:53:34,711:INFO:            imblearn: 0.13.0
2025-06-27 15:53:34,711:INFO:   category_encoders: 2.7.0
2025-06-27 15:53:34,711:INFO:            lightgbm: 4.6.0
2025-06-27 15:53:34,711:INFO:               numba: 0.61.2
2025-06-27 15:53:34,712:INFO:            requests: 2.32.4
2025-06-27 15:53:34,712:INFO:          matplotlib: 3.7.5
2025-06-27 15:53:34,712:INFO:          scikitplot: 0.3.7
2025-06-27 15:53:34,712:INFO:         yellowbrick: 1.5
2025-06-27 15:53:34,712:INFO:              plotly: 5.24.1
2025-06-27 15:53:34,712:INFO:    plotly-resampler: Not installed
2025-06-27 15:53:34,712:INFO:             kaleido: 1.0.0
2025-06-27 15:53:34,712:INFO:           schemdraw: 0.15
2025-06-27 15:53:34,712:INFO:         statsmodels: 0.14.4
2025-06-27 15:53:34,712:INFO:              sktime: 0.26.0
2025-06-27 15:53:34,712:INFO:               tbats: 1.1.3
2025-06-27 15:53:34,712:INFO:            pmdarima: 2.0.4
2025-06-27 15:53:34,712:INFO:              psutil: 7.0.0
2025-06-27 15:53:34,712:INFO:          markupsafe: 3.0.2
2025-06-27 15:53:34,712:INFO:             pickle5: Not installed
2025-06-27 15:53:34,712:INFO:         cloudpickle: 3.1.1
2025-06-27 15:53:34,712:INFO:         deprecation: 2.1.0
2025-06-27 15:53:34,712:INFO:              xxhash: 3.5.0
2025-06-27 15:53:34,712:INFO:           wurlitzer: Not installed
2025-06-27 15:53:34,712:INFO:PyCaret optional dependencies:
2025-06-27 15:53:34,724:INFO:                shap: Not installed
2025-06-27 15:53:34,724:INFO:           interpret: Not installed
2025-06-27 15:53:34,724:INFO:                umap: Not installed
2025-06-27 15:53:34,724:INFO:     ydata_profiling: Not installed
2025-06-27 15:53:34,724:INFO:  explainerdashboard: Not installed
2025-06-27 15:53:34,724:INFO:             autoviz: Not installed
2025-06-27 15:53:34,724:INFO:           fairlearn: Not installed
2025-06-27 15:53:34,724:INFO:          deepchecks: Not installed
2025-06-27 15:53:34,724:INFO:             xgboost: Not installed
2025-06-27 15:53:34,724:INFO:            catboost: Not installed
2025-06-27 15:53:34,724:INFO:              kmodes: Not installed
2025-06-27 15:53:34,724:INFO:             mlxtend: Not installed
2025-06-27 15:53:34,724:INFO:       statsforecast: Not installed
2025-06-27 15:53:34,724:INFO:        tune_sklearn: Not installed
2025-06-27 15:53:34,724:INFO:                 ray: Not installed
2025-06-27 15:53:34,724:INFO:            hyperopt: Not installed
2025-06-27 15:53:34,724:INFO:              optuna: Not installed
2025-06-27 15:53:34,724:INFO:               skopt: Not installed
2025-06-27 15:53:34,724:INFO:              mlflow: Not installed
2025-06-27 15:53:34,724:INFO:              gradio: Not installed
2025-06-27 15:53:34,724:INFO:             fastapi: Not installed
2025-06-27 15:53:34,724:INFO:             uvicorn: Not installed
2025-06-27 15:53:34,724:INFO:              m2cgen: Not installed
2025-06-27 15:53:34,724:INFO:           evidently: Not installed
2025-06-27 15:53:34,724:INFO:               fugue: Not installed
2025-06-27 15:53:34,724:INFO:           streamlit: Not installed
2025-06-27 15:53:34,724:INFO:             prophet: Not installed
2025-06-27 15:53:34,724:INFO:None
2025-06-27 15:53:34,724:INFO:Set up data.
2025-06-27 15:53:34,734:INFO:Set up folding strategy.
2025-06-27 15:53:34,734:INFO:Set up train/test split.
2025-06-27 15:53:34,774:INFO:Set up index.
2025-06-27 15:53:34,774:INFO:Assigning column types.
2025-06-27 15:53:34,782:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-27 15:53:34,831:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 15:53:34,834:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:53:34,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:34,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:34,918:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 15:53:34,918:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:53:34,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:34,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:34,942:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-27 15:53:34,988:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:53:35,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,069:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:53:35,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,097:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-27 15:53:35,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,250:INFO:Preparing preprocessing pipeline...
2025-06-27 15:53:35,254:INFO:Set up simple imputation.
2025-06-27 15:53:35,254:INFO:Set up encoding of ordinal features.
2025-06-27 15:53:35,259:INFO:Set up encoding of categorical features.
2025-06-27 15:53:35,259:INFO:Set up polynomial features.
2025-06-27 15:53:35,259:INFO:Set up removing multicollinearity.
2025-06-27 15:53:35,259:INFO:Set up feature normalization.
2025-06-27 15:53:35,482:INFO:Finished creating preprocessing pipeline.
2025-06-27 15:53:35,503:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imp...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-06-27 15:53:35,503:INFO:Creating final display dataframe.
2025-06-27 15:53:35,662:INFO:Setup _display_container:                     Description                    Value
0                    Session id                      124
1                        Target                 Survived
2                   Target type                   Binary
3           Original data shape                (712, 12)
4        Transformed data shape                (712, 53)
5   Transformed train set shape                (498, 53)
6    Transformed test set shape                (214, 53)
7              Numeric features                        6
8          Categorical features                        5
9      Rows with missing values                    79.9%
10                   Preprocess                     True
11              Imputation type                   simple
12           Numeric imputation                     mean
13       Categorical imputation                     mode
14     Maximum one-hot encoding                       25
15              Encoding method                     None
16          Polynomial features                     True
17            Polynomial degree                        2
18     Remove multicollinearity                     True
19  Multicollinearity threshold                      0.9
20                    Normalize                     True
21             Normalize method                   zscore
22               Fold Generator          StratifiedKFold
23                  Fold Number                       10
24                     CPU Jobs                       -1
25                      Use GPU                    False
26               Log Experiment                    False
27              Experiment Name  Survived_classification
28                          USI                     b0f8
2025-06-27 15:53:35,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,824:INFO:setup() successfully completed in 1.19s...............
2025-06-27 15:53:35,835:INFO:gpu_param set to False
2025-06-27 15:53:35,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:35,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:36,050:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:36,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:53:36,068:INFO:Initializing compare_models()
2025-06-27 15:53:36,068:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, include=['dt'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, 'include': ['dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-06-27 15:53:36,068:INFO:Checking exceptions
2025-06-27 15:53:36,077:INFO:Preparing display monitor
2025-06-27 15:53:36,107:INFO:Initializing Decision Tree Classifier
2025-06-27 15:53:36,109:INFO:Total runtime is 3.345807393391927e-05 minutes
2025-06-27 15:53:36,115:INFO:SubProcess create_model() called ==================================
2025-06-27 15:53:36,115:INFO:Initializing create_model()
2025-06-27 15:53:36,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000210787FF010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:53:36,116:INFO:Checking exceptions
2025-06-27 15:53:36,116:INFO:Importing libraries
2025-06-27 15:53:36,116:INFO:Copying training dataset
2025-06-27 15:53:36,125:INFO:Defining folds
2025-06-27 15:53:36,125:INFO:Declaring metric variables
2025-06-27 15:53:36,130:INFO:Importing untrained model
2025-06-27 15:53:36,137:INFO:Decision Tree Classifier Imported successfully
2025-06-27 15:53:36,145:INFO:Starting cross validation
2025-06-27 15:53:36,149:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:53:41,686:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:53:41,688:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:53:41,768:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:53:42,397:INFO:Calculating mean and std
2025-06-27 15:53:42,397:INFO:Creating metrics dataframe
2025-06-27 15:53:42,399:INFO:Uploading results into container
2025-06-27 15:53:42,399:INFO:Uploading model into container now
2025-06-27 15:53:42,401:INFO:_master_model_container: 1
2025-06-27 15:53:42,401:INFO:_display_container: 2
2025-06-27 15:53:42,401:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best')
2025-06-27 15:53:42,401:INFO:create_model() successfully completed......................................
2025-06-27 15:53:42,497:INFO:SubProcess create_model() end ==================================
2025-06-27 15:53:42,497:INFO:Creating metrics dataframe
2025-06-27 15:53:42,547:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-06-27 15:53:42,559:INFO:Initializing create_model()
2025-06-27 15:53:42,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:53:42,559:INFO:Checking exceptions
2025-06-27 15:53:42,561:INFO:Importing libraries
2025-06-27 15:53:42,561:INFO:Copying training dataset
2025-06-27 15:53:42,567:INFO:Defining folds
2025-06-27 15:53:42,567:INFO:Declaring metric variables
2025-06-27 15:53:42,567:INFO:Importing untrained model
2025-06-27 15:53:42,567:INFO:Declaring custom model
2025-06-27 15:53:42,567:INFO:Decision Tree Classifier Imported successfully
2025-06-27 15:53:42,567:INFO:Cross validation set to False
2025-06-27 15:53:42,567:INFO:Fitting Model
2025-06-27 15:53:42,699:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best')
2025-06-27 15:53:42,699:INFO:create_model() successfully completed......................................
2025-06-27 15:53:42,807:INFO:_master_model_container: 1
2025-06-27 15:53:42,807:INFO:_display_container: 2
2025-06-27 15:53:42,807:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best')
2025-06-27 15:53:42,807:INFO:compare_models() successfully completed......................................
2025-06-27 15:53:42,854:INFO:Initializing tune_model()
2025-06-27 15:53:42,854:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-06-27 15:53:42,854:INFO:Checking exceptions
2025-06-27 15:53:42,874:INFO:Copying training dataset
2025-06-27 15:53:42,878:INFO:Checking base model
2025-06-27 15:53:42,879:INFO:Base model : Decision Tree Classifier
2025-06-27 15:53:42,884:INFO:Declaring metric variables
2025-06-27 15:53:42,888:INFO:Defining Hyperparameters
2025-06-27 15:53:43,004:INFO:Tuning with n_jobs=-1
2025-06-27 15:53:43,004:INFO:Initializing RandomizedSearchCV
2025-06-27 15:53:48,656:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 13, 'actual_estimator__criterion': 'gini'}
2025-06-27 15:53:48,658:INFO:Hyperparameter search completed
2025-06-27 15:53:48,658:INFO:SubProcess create_model() called ==================================
2025-06-27 15:53:48,658:INFO:Initializing create_model()
2025-06-27 15:53:48,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000210547C8C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0002, 'max_features': 'log2', 'max_depth': 13, 'criterion': 'gini'})
2025-06-27 15:53:48,660:INFO:Checking exceptions
2025-06-27 15:53:48,660:INFO:Importing libraries
2025-06-27 15:53:48,660:INFO:Copying training dataset
2025-06-27 15:53:48,669:INFO:Defining folds
2025-06-27 15:53:48,669:INFO:Declaring metric variables
2025-06-27 15:53:48,675:INFO:Importing untrained model
2025-06-27 15:53:48,675:INFO:Declaring custom model
2025-06-27 15:53:48,678:INFO:Decision Tree Classifier Imported successfully
2025-06-27 15:53:48,691:INFO:Starting cross validation
2025-06-27 15:53:48,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:53:49,122:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:53:49,129:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:53:49,177:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:53:49,200:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:53:49,448:INFO:Calculating mean and std
2025-06-27 15:53:49,449:INFO:Creating metrics dataframe
2025-06-27 15:53:49,454:INFO:Finalizing model
2025-06-27 15:53:49,621:INFO:Uploading results into container
2025-06-27 15:53:49,621:INFO:Uploading model into container now
2025-06-27 15:53:49,623:INFO:_master_model_container: 2
2025-06-27 15:53:49,623:INFO:_display_container: 3
2025-06-27 15:53:49,623:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=13, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best')
2025-06-27 15:53:49,623:INFO:create_model() successfully completed......................................
2025-06-27 15:53:49,704:INFO:SubProcess create_model() end ==================================
2025-06-27 15:53:49,704:INFO:choose_better activated
2025-06-27 15:53:49,709:INFO:SubProcess create_model() called ==================================
2025-06-27 15:53:49,710:INFO:Initializing create_model()
2025-06-27 15:53:49,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:53:49,710:INFO:Checking exceptions
2025-06-27 15:53:49,712:INFO:Importing libraries
2025-06-27 15:53:49,712:INFO:Copying training dataset
2025-06-27 15:53:49,715:INFO:Defining folds
2025-06-27 15:53:49,715:INFO:Declaring metric variables
2025-06-27 15:53:49,715:INFO:Importing untrained model
2025-06-27 15:53:49,715:INFO:Declaring custom model
2025-06-27 15:53:49,715:INFO:Decision Tree Classifier Imported successfully
2025-06-27 15:53:49,715:INFO:Starting cross validation
2025-06-27 15:53:49,715:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:53:50,102:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:53:50,114:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:53:50,121:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:53:50,381:INFO:Calculating mean and std
2025-06-27 15:53:50,383:INFO:Creating metrics dataframe
2025-06-27 15:53:50,388:INFO:Finalizing model
2025-06-27 15:53:50,554:INFO:Uploading results into container
2025-06-27 15:53:50,560:INFO:Uploading model into container now
2025-06-27 15:53:50,560:INFO:_master_model_container: 3
2025-06-27 15:53:50,560:INFO:_display_container: 4
2025-06-27 15:53:50,560:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best')
2025-06-27 15:53:50,560:INFO:create_model() successfully completed......................................
2025-06-27 15:53:50,644:INFO:SubProcess create_model() end ==================================
2025-06-27 15:53:50,644:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best') result for Accuracy is 0.6669
2025-06-27 15:53:50,646:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=13, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best') result for Accuracy is 0.6869
2025-06-27 15:53:50,648:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=13, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best') is best model
2025-06-27 15:53:50,648:INFO:choose_better completed
2025-06-27 15:53:50,673:INFO:_master_model_container: 3
2025-06-27 15:53:50,674:INFO:_display_container: 3
2025-06-27 15:53:50,675:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=13, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best')
2025-06-27 15:53:50,675:INFO:tune_model() successfully completed......................................
2025-06-27 15:53:50,810:INFO:Initializing evaluate_model()
2025-06-27 15:53:50,810:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=13, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-27 15:53:50,826:INFO:Initializing plot_model()
2025-06-27 15:53:50,826:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=13, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-06-27 15:53:50,827:INFO:Checking exceptions
2025-06-27 15:53:50,830:INFO:Preloading libraries
2025-06-27 15:53:50,830:INFO:Copying training dataset
2025-06-27 15:53:50,830:INFO:Plot type: pipeline
2025-06-27 15:53:51,232:INFO:Visual Rendered Successfully
2025-06-27 15:53:51,314:INFO:plot_model() successfully completed......................................
2025-06-27 15:53:51,339:INFO:Initializing finalize_model()
2025-06-27 15:53:51,340:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=13, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-27 15:53:51,340:INFO:Finalizing DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=13, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best')
2025-06-27 15:53:51,345:INFO:Initializing create_model()
2025-06-27 15:53:51,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=13, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=124, splitter='best'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:53:51,345:INFO:Checking exceptions
2025-06-27 15:53:51,347:INFO:Importing libraries
2025-06-27 15:53:51,347:INFO:Copying training dataset
2025-06-27 15:53:51,349:INFO:Defining folds
2025-06-27 15:53:51,349:INFO:Declaring metric variables
2025-06-27 15:53:51,349:INFO:Importing untrained model
2025-06-27 15:53:51,349:INFO:Declaring custom model
2025-06-27 15:53:51,350:INFO:Decision Tree Classifier Imported successfully
2025-06-27 15:53:51,352:INFO:Cross validation set to False
2025-06-27 15:53:51,352:INFO:Fitting Model
2025-06-27 15:53:51,500:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=13,
                                        max_features='log2',
                                        max_leaf_nodes=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=2, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=124,
                                        splitter='best'))],
         verbose=False)
2025-06-27 15:53:51,500:INFO:create_model() successfully completed......................................
2025-06-27 15:53:51,583:INFO:_master_model_container: 3
2025-06-27 15:53:51,584:INFO:_display_container: 3
2025-06-27 15:53:51,615:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=13,
                                        max_features='log2',
                                        max_leaf_nodes=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=2, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=124,
                                        splitter='best'))],
         verbose=False)
2025-06-27 15:53:51,615:INFO:finalize_model() successfully completed......................................
2025-06-27 15:53:51,821:INFO:Initializing predict_model()
2025-06-27 15:53:51,821:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021078502D50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=13,
                                        max_features='log2',
                                        max_leaf_nodes=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=2, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=124,
                                        splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000210787C8360>)
2025-06-27 15:53:51,821:INFO:Checking exceptions
2025-06-27 15:53:51,821:INFO:Preloading libraries
2025-06-27 15:53:51,824:INFO:Set up data.
2025-06-27 15:53:51,831:INFO:Set up index.
2025-06-27 15:53:52,085:INFO:Initializing save_model()
2025-06-27 15:53:52,086:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=13,
                                        max_features='log2',
                                        max_leaf_nodes=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=2, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=124,
                                        splitter='best'))],
         verbose=False), model_name=final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imp...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-06-27 15:53:52,086:INFO:Adding model into prep_pipe
2025-06-27 15:53:52,086:WARNING:Only Model saved as it was a pipeline.
2025-06-27 15:53:52,100:INFO:final_model.pkl saved in current working directory
2025-06-27 15:53:52,124:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=13,
                                        max_features='log2',
                                        max_leaf_nodes=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=2, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=124,
                                        splitter='best'))],
         verbose=False)
2025-06-27 15:53:52,124:INFO:save_model() successfully completed......................................
2025-06-27 15:53:52,271:INFO:Initializing load_model()
2025-06-27 15:53:52,271:INFO:load_model(model_name=final_model, platform=None, authentication=None, verbose=True)
2025-06-27 15:54:09,772:INFO:PyCaret ClassificationExperiment
2025-06-27 15:54:09,772:INFO:Logging name: Survived_classification
2025-06-27 15:54:09,772:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-27 15:54:09,772:INFO:version 3.3.2
2025-06-27 15:54:09,772:INFO:Initializing setup()
2025-06-27 15:54:09,772:INFO:self.USI: b717
2025-06-27 15:54:09,772:INFO:self._variable_keys: {'X_test', 'gpu_param', 'data', 'USI', 'pipeline', 'fold_generator', 'X', 'fix_imbalance', 'y', 'html_param', 'X_train', 'y_train', 'idx', 'y_test', 'fold_groups_param', 'n_jobs_param', 'exp_id', 'target_param', 'logging_param', 'exp_name_log', '_available_plots', 'memory', 'gpu_n_jobs_param', 'fold_shuffle_param', 'seed', 'is_multiclass', 'log_plots_param', '_ml_usecase'}
2025-06-27 15:54:09,772:INFO:Checking environment
2025-06-27 15:54:09,772:INFO:python_version: 3.11.9
2025-06-27 15:54:09,774:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-27 15:54:09,774:INFO:machine: AMD64
2025-06-27 15:54:09,774:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-27 15:54:09,780:INFO:Memory: svmem(total=34156609536, available=15343173632, percent=55.1, used=18813435904, free=15343173632)
2025-06-27 15:54:09,780:INFO:Physical Core: 4
2025-06-27 15:54:09,780:INFO:Logical Core: 8
2025-06-27 15:54:09,780:INFO:Checking libraries
2025-06-27 15:54:09,780:INFO:System:
2025-06-27 15:54:09,780:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-27 15:54:09,780:INFO:executable: c:\Users\hp\Downloads\titanic\venv55412\Scripts\python.exe
2025-06-27 15:54:09,780:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-27 15:54:09,780:INFO:PyCaret required dependencies:
2025-06-27 15:54:09,780:INFO:                 pip: 24.0
2025-06-27 15:54:09,780:INFO:          setuptools: 65.5.0
2025-06-27 15:54:09,780:INFO:             pycaret: 3.3.2
2025-06-27 15:54:09,780:INFO:             IPython: 9.3.0
2025-06-27 15:54:09,780:INFO:          ipywidgets: 8.1.7
2025-06-27 15:54:09,780:INFO:                tqdm: 4.67.1
2025-06-27 15:54:09,780:INFO:               numpy: 1.26.4
2025-06-27 15:54:09,780:INFO:              pandas: 2.1.4
2025-06-27 15:54:09,780:INFO:              jinja2: 3.1.6
2025-06-27 15:54:09,780:INFO:               scipy: 1.11.4
2025-06-27 15:54:09,780:INFO:              joblib: 1.3.2
2025-06-27 15:54:09,780:INFO:             sklearn: 1.4.2
2025-06-27 15:54:09,780:INFO:                pyod: 2.0.5
2025-06-27 15:54:09,780:INFO:            imblearn: 0.13.0
2025-06-27 15:54:09,780:INFO:   category_encoders: 2.7.0
2025-06-27 15:54:09,782:INFO:            lightgbm: 4.6.0
2025-06-27 15:54:09,782:INFO:               numba: 0.61.2
2025-06-27 15:54:09,782:INFO:            requests: 2.32.4
2025-06-27 15:54:09,782:INFO:          matplotlib: 3.7.5
2025-06-27 15:54:09,782:INFO:          scikitplot: 0.3.7
2025-06-27 15:54:09,782:INFO:         yellowbrick: 1.5
2025-06-27 15:54:09,782:INFO:              plotly: 5.24.1
2025-06-27 15:54:09,782:INFO:    plotly-resampler: Not installed
2025-06-27 15:54:09,782:INFO:             kaleido: 1.0.0
2025-06-27 15:54:09,782:INFO:           schemdraw: 0.15
2025-06-27 15:54:09,782:INFO:         statsmodels: 0.14.4
2025-06-27 15:54:09,782:INFO:              sktime: 0.26.0
2025-06-27 15:54:09,782:INFO:               tbats: 1.1.3
2025-06-27 15:54:09,782:INFO:            pmdarima: 2.0.4
2025-06-27 15:54:09,782:INFO:              psutil: 7.0.0
2025-06-27 15:54:09,782:INFO:          markupsafe: 3.0.2
2025-06-27 15:54:09,782:INFO:             pickle5: Not installed
2025-06-27 15:54:09,782:INFO:         cloudpickle: 3.1.1
2025-06-27 15:54:09,782:INFO:         deprecation: 2.1.0
2025-06-27 15:54:09,782:INFO:              xxhash: 3.5.0
2025-06-27 15:54:09,782:INFO:           wurlitzer: Not installed
2025-06-27 15:54:09,782:INFO:PyCaret optional dependencies:
2025-06-27 15:54:09,782:INFO:                shap: Not installed
2025-06-27 15:54:09,783:INFO:           interpret: Not installed
2025-06-27 15:54:09,783:INFO:                umap: Not installed
2025-06-27 15:54:09,783:INFO:     ydata_profiling: Not installed
2025-06-27 15:54:09,783:INFO:  explainerdashboard: Not installed
2025-06-27 15:54:09,783:INFO:             autoviz: Not installed
2025-06-27 15:54:09,783:INFO:           fairlearn: Not installed
2025-06-27 15:54:09,783:INFO:          deepchecks: Not installed
2025-06-27 15:54:09,783:INFO:             xgboost: Not installed
2025-06-27 15:54:09,783:INFO:            catboost: Not installed
2025-06-27 15:54:09,783:INFO:              kmodes: Not installed
2025-06-27 15:54:09,783:INFO:             mlxtend: Not installed
2025-06-27 15:54:09,783:INFO:       statsforecast: Not installed
2025-06-27 15:54:09,783:INFO:        tune_sklearn: Not installed
2025-06-27 15:54:09,783:INFO:                 ray: Not installed
2025-06-27 15:54:09,783:INFO:            hyperopt: Not installed
2025-06-27 15:54:09,783:INFO:              optuna: Not installed
2025-06-27 15:54:09,783:INFO:               skopt: Not installed
2025-06-27 15:54:09,783:INFO:              mlflow: Not installed
2025-06-27 15:54:09,783:INFO:              gradio: Not installed
2025-06-27 15:54:09,783:INFO:             fastapi: Not installed
2025-06-27 15:54:09,783:INFO:             uvicorn: Not installed
2025-06-27 15:54:09,783:INFO:              m2cgen: Not installed
2025-06-27 15:54:09,783:INFO:           evidently: Not installed
2025-06-27 15:54:09,783:INFO:               fugue: Not installed
2025-06-27 15:54:09,783:INFO:           streamlit: Not installed
2025-06-27 15:54:09,783:INFO:             prophet: Not installed
2025-06-27 15:54:09,783:INFO:None
2025-06-27 15:54:09,783:INFO:Set up data.
2025-06-27 15:54:09,798:INFO:Set up folding strategy.
2025-06-27 15:54:09,798:INFO:Set up train/test split.
2025-06-27 15:54:09,807:INFO:Set up index.
2025-06-27 15:54:09,807:INFO:Assigning column types.
2025-06-27 15:54:09,815:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-27 15:54:09,922:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 15:54:09,923:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:54:09,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:09,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:09,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 15:54:09,999:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:54:10,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:10,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:10,027:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-27 15:54:10,072:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:54:10,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:10,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:10,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:54:10,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:10,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:10,172:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-27 15:54:10,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:10,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:10,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:10,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:10,318:INFO:Preparing preprocessing pipeline...
2025-06-27 15:54:10,320:INFO:Set up simple imputation.
2025-06-27 15:54:10,324:INFO:Set up encoding of ordinal features.
2025-06-27 15:54:10,326:INFO:Set up encoding of categorical features.
2025-06-27 15:54:10,326:INFO:Set up polynomial features.
2025-06-27 15:54:10,326:INFO:Set up removing multicollinearity.
2025-06-27 15:54:10,326:INFO:Set up feature normalization.
2025-06-27 15:54:10,524:INFO:Finished creating preprocessing pipeline.
2025-06-27 15:54:10,544:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imp...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-06-27 15:54:10,544:INFO:Creating final display dataframe.
2025-06-27 15:54:10,973:INFO:Setup _display_container:                     Description                    Value
0                    Session id                      546
1                        Target                 Survived
2                   Target type                   Binary
3           Original data shape                (712, 12)
4        Transformed data shape                (712, 50)
5   Transformed train set shape                (498, 50)
6    Transformed test set shape                (214, 50)
7              Numeric features                        6
8          Categorical features                        5
9      Rows with missing values                    79.9%
10                   Preprocess                     True
11              Imputation type                   simple
12           Numeric imputation                     mean
13       Categorical imputation                     mode
14     Maximum one-hot encoding                       25
15              Encoding method                     None
16          Polynomial features                     True
17            Polynomial degree                        2
18     Remove multicollinearity                     True
19  Multicollinearity threshold                      0.9
20                    Normalize                     True
21             Normalize method                   zscore
22               Fold Generator          StratifiedKFold
23                  Fold Number                       10
24                     CPU Jobs                       -1
25                      Use GPU                    False
26               Log Experiment                    False
27              Experiment Name  Survived_classification
28                          USI                     b717
2025-06-27 15:54:11,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:11,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:11,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:11,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:11,113:INFO:setup() successfully completed in 1.35s...............
2025-06-27 15:54:11,134:INFO:gpu_param set to False
2025-06-27 15:54:11,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:11,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:11,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:11,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:54:11,308:INFO:Initializing compare_models()
2025-06-27 15:54:11,308:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, include=['dt'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, 'include': ['dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-06-27 15:54:11,308:INFO:Checking exceptions
2025-06-27 15:54:11,313:INFO:Preparing display monitor
2025-06-27 15:54:11,341:INFO:Initializing Decision Tree Classifier
2025-06-27 15:54:11,341:INFO:Total runtime is 0.0 minutes
2025-06-27 15:54:11,348:INFO:SubProcess create_model() called ==================================
2025-06-27 15:54:11,348:INFO:Initializing create_model()
2025-06-27 15:54:11,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021078CBE050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:54:11,349:INFO:Checking exceptions
2025-06-27 15:54:11,349:INFO:Importing libraries
2025-06-27 15:54:11,349:INFO:Copying training dataset
2025-06-27 15:54:11,357:INFO:Defining folds
2025-06-27 15:54:11,357:INFO:Declaring metric variables
2025-06-27 15:54:11,363:INFO:Importing untrained model
2025-06-27 15:54:11,367:INFO:Decision Tree Classifier Imported successfully
2025-06-27 15:54:11,378:INFO:Starting cross validation
2025-06-27 15:54:11,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:54:11,740:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:54:11,747:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:54:11,908:INFO:Calculating mean and std
2025-06-27 15:54:11,908:INFO:Creating metrics dataframe
2025-06-27 15:54:11,908:INFO:Uploading results into container
2025-06-27 15:54:11,908:INFO:Uploading model into container now
2025-06-27 15:54:11,908:INFO:_master_model_container: 1
2025-06-27 15:54:11,908:INFO:_display_container: 2
2025-06-27 15:54:11,911:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best')
2025-06-27 15:54:11,911:INFO:create_model() successfully completed......................................
2025-06-27 15:54:11,988:INFO:SubProcess create_model() end ==================================
2025-06-27 15:54:11,988:INFO:Creating metrics dataframe
2025-06-27 15:54:11,995:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-06-27 15:54:12,007:INFO:Initializing create_model()
2025-06-27 15:54:12,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:54:12,011:INFO:Checking exceptions
2025-06-27 15:54:12,013:INFO:Importing libraries
2025-06-27 15:54:12,013:INFO:Copying training dataset
2025-06-27 15:54:12,014:INFO:Defining folds
2025-06-27 15:54:12,014:INFO:Declaring metric variables
2025-06-27 15:54:12,014:INFO:Importing untrained model
2025-06-27 15:54:12,014:INFO:Declaring custom model
2025-06-27 15:54:12,014:INFO:Decision Tree Classifier Imported successfully
2025-06-27 15:54:12,021:INFO:Cross validation set to False
2025-06-27 15:54:12,021:INFO:Fitting Model
2025-06-27 15:54:12,149:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best')
2025-06-27 15:54:12,154:INFO:create_model() successfully completed......................................
2025-06-27 15:54:12,245:INFO:_master_model_container: 1
2025-06-27 15:54:12,245:INFO:_display_container: 2
2025-06-27 15:54:12,245:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best')
2025-06-27 15:54:12,245:INFO:compare_models() successfully completed......................................
2025-06-27 15:54:12,282:INFO:Initializing tune_model()
2025-06-27 15:54:12,282:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-06-27 15:54:12,282:INFO:Checking exceptions
2025-06-27 15:54:12,304:INFO:Copying training dataset
2025-06-27 15:54:12,308:INFO:Checking base model
2025-06-27 15:54:12,308:INFO:Base model : Decision Tree Classifier
2025-06-27 15:54:12,319:INFO:Declaring metric variables
2025-06-27 15:54:12,327:INFO:Defining Hyperparameters
2025-06-27 15:54:12,424:INFO:Tuning with n_jobs=-1
2025-06-27 15:54:12,424:INFO:Initializing RandomizedSearchCV
2025-06-27 15:54:18,799:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'entropy'}
2025-06-27 15:54:18,800:INFO:Hyperparameter search completed
2025-06-27 15:54:18,800:INFO:SubProcess create_model() called ==================================
2025-06-27 15:54:18,801:INFO:Initializing create_model()
2025-06-27 15:54:18,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000210786E3510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0005, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'entropy'})
2025-06-27 15:54:18,802:INFO:Checking exceptions
2025-06-27 15:54:18,802:INFO:Importing libraries
2025-06-27 15:54:18,802:INFO:Copying training dataset
2025-06-27 15:54:18,813:INFO:Defining folds
2025-06-27 15:54:18,815:INFO:Declaring metric variables
2025-06-27 15:54:18,819:INFO:Importing untrained model
2025-06-27 15:54:18,819:INFO:Declaring custom model
2025-06-27 15:54:18,828:INFO:Decision Tree Classifier Imported successfully
2025-06-27 15:54:18,838:INFO:Starting cross validation
2025-06-27 15:54:18,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:54:19,318:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:54:19,387:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:54:19,719:INFO:Calculating mean and std
2025-06-27 15:54:19,721:INFO:Creating metrics dataframe
2025-06-27 15:54:19,731:INFO:Finalizing model
2025-06-27 15:54:19,929:INFO:Uploading results into container
2025-06-27 15:54:19,931:INFO:Uploading model into container now
2025-06-27 15:54:19,931:INFO:_master_model_container: 2
2025-06-27 15:54:19,931:INFO:_display_container: 3
2025-06-27 15:54:19,933:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best')
2025-06-27 15:54:19,933:INFO:create_model() successfully completed......................................
2025-06-27 15:54:20,017:INFO:SubProcess create_model() end ==================================
2025-06-27 15:54:20,017:INFO:choose_better activated
2025-06-27 15:54:20,022:INFO:SubProcess create_model() called ==================================
2025-06-27 15:54:20,023:INFO:Initializing create_model()
2025-06-27 15:54:20,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:54:20,024:INFO:Checking exceptions
2025-06-27 15:54:20,026:INFO:Importing libraries
2025-06-27 15:54:20,026:INFO:Copying training dataset
2025-06-27 15:54:20,032:INFO:Defining folds
2025-06-27 15:54:20,032:INFO:Declaring metric variables
2025-06-27 15:54:20,032:INFO:Importing untrained model
2025-06-27 15:54:20,032:INFO:Declaring custom model
2025-06-27 15:54:20,034:INFO:Decision Tree Classifier Imported successfully
2025-06-27 15:54:20,034:INFO:Starting cross validation
2025-06-27 15:54:20,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:54:20,630:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:54:20,698:WARNING:c:\Users\hp\Downloads\titanic\venv55412\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:54:20,887:INFO:Calculating mean and std
2025-06-27 15:54:20,887:INFO:Creating metrics dataframe
2025-06-27 15:54:20,890:INFO:Finalizing model
2025-06-27 15:54:21,078:INFO:Uploading results into container
2025-06-27 15:54:21,078:INFO:Uploading model into container now
2025-06-27 15:54:21,079:INFO:_master_model_container: 3
2025-06-27 15:54:21,079:INFO:_display_container: 4
2025-06-27 15:54:21,079:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best')
2025-06-27 15:54:21,080:INFO:create_model() successfully completed......................................
2025-06-27 15:54:21,157:INFO:SubProcess create_model() end ==================================
2025-06-27 15:54:21,157:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best') result for Accuracy is 0.6608
2025-06-27 15:54:21,157:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best') result for Accuracy is 0.6687
2025-06-27 15:54:21,157:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best') is best model
2025-06-27 15:54:21,164:INFO:choose_better completed
2025-06-27 15:54:21,176:INFO:_master_model_container: 3
2025-06-27 15:54:21,176:INFO:_display_container: 3
2025-06-27 15:54:21,176:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best')
2025-06-27 15:54:21,176:INFO:tune_model() successfully completed......................................
2025-06-27 15:54:21,310:INFO:Initializing evaluate_model()
2025-06-27 15:54:21,311:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-27 15:54:21,326:INFO:Initializing plot_model()
2025-06-27 15:54:21,326:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-06-27 15:54:21,326:INFO:Checking exceptions
2025-06-27 15:54:21,330:INFO:Preloading libraries
2025-06-27 15:54:21,330:INFO:Copying training dataset
2025-06-27 15:54:21,330:INFO:Plot type: pipeline
2025-06-27 15:54:21,664:INFO:Visual Rendered Successfully
2025-06-27 15:54:21,745:INFO:plot_model() successfully completed......................................
2025-06-27 15:54:21,781:INFO:Initializing finalize_model()
2025-06-27 15:54:21,782:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-27 15:54:21,784:INFO:Finalizing DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best')
2025-06-27 15:54:21,792:INFO:Initializing create_model()
2025-06-27 15:54:21,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=546, splitter='best'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:54:21,792:INFO:Checking exceptions
2025-06-27 15:54:21,795:INFO:Importing libraries
2025-06-27 15:54:21,796:INFO:Copying training dataset
2025-06-27 15:54:21,796:INFO:Defining folds
2025-06-27 15:54:21,796:INFO:Declaring metric variables
2025-06-27 15:54:21,797:INFO:Importing untrained model
2025-06-27 15:54:21,797:INFO:Declaring custom model
2025-06-27 15:54:21,798:INFO:Decision Tree Classifier Imported successfully
2025-06-27 15:54:21,802:INFO:Cross validation set to False
2025-06-27 15:54:21,802:INFO:Fitting Model
2025-06-27 15:54:22,163:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='entropy', max_depth=11,
                                        max_features='sqrt',
                                        max_leaf_nodes=None,
                                        min_impurity_decrease=0.0005,
                                        min_samples_leaf=4, min_samples_split=5,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=546,
                                        splitter='best'))],
         verbose=False)
2025-06-27 15:54:22,163:INFO:create_model() successfully completed......................................
2025-06-27 15:54:22,251:INFO:_master_model_container: 3
2025-06-27 15:54:22,251:INFO:_display_container: 3
2025-06-27 15:54:22,282:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='entropy', max_depth=11,
                                        max_features='sqrt',
                                        max_leaf_nodes=None,
                                        min_impurity_decrease=0.0005,
                                        min_samples_leaf=4, min_samples_split=5,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=546,
                                        splitter='best'))],
         verbose=False)
2025-06-27 15:54:22,282:INFO:finalize_model() successfully completed......................................
2025-06-27 15:54:22,544:INFO:Initializing predict_model()
2025-06-27 15:54:22,544:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000210787CF790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='entropy', max_depth=11,
                                        max_features='sqrt',
                                        max_leaf_nodes=None,
                                        min_impurity_decrease=0.0005,
                                        min_samples_leaf=4, min_samples_split=5,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=546,
                                        splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021052E41300>)
2025-06-27 15:54:22,544:INFO:Checking exceptions
2025-06-27 15:54:22,544:INFO:Preloading libraries
2025-06-27 15:54:22,551:INFO:Set up data.
2025-06-27 15:54:22,568:INFO:Set up index.
2025-06-27 15:54:22,931:INFO:Initializing save_model()
2025-06-27 15:54:22,931:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='entropy', max_depth=11,
                                        max_features='sqrt',
                                        max_leaf_nodes=None,
                                        min_impurity_decrease=0.0005,
                                        min_samples_leaf=4, min_samples_split=5,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=546,
                                        splitter='best'))],
         verbose=False), model_name=final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imp...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-06-27 15:54:22,932:INFO:Adding model into prep_pipe
2025-06-27 15:54:22,932:WARNING:Only Model saved as it was a pipeline.
2025-06-27 15:54:22,948:INFO:final_model.pkl saved in current working directory
2025-06-27 15:54:22,974:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='entropy', max_depth=11,
                                        max_features='sqrt',
                                        max_leaf_nodes=None,
                                        min_impurity_decrease=0.0005,
                                        min_samples_leaf=4, min_samples_split=5,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=546,
                                        splitter='best'))],
         verbose=False)
2025-06-27 15:54:22,974:INFO:save_model() successfully completed......................................
2025-06-27 15:54:23,144:INFO:Initializing load_model()
2025-06-27 15:54:23,144:INFO:load_model(model_name=final_model, platform=None, authentication=None, verbose=True)
